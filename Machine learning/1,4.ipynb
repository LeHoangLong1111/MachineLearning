{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usual</th>\n",
       "      <th>proper</th>\n",
       "      <th>complete</th>\n",
       "      <th>1</th>\n",
       "      <th>convenient</th>\n",
       "      <th>convenient.1</th>\n",
       "      <th>nonprob</th>\n",
       "      <th>recommended</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12954</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12959 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            usual     proper  complete     1  convenient convenient.1  \\\n",
       "0           usual     proper  complete     1  convenient   convenient   \n",
       "1           usual     proper  complete     1  convenient   convenient   \n",
       "2           usual     proper  complete     1  convenient   convenient   \n",
       "3           usual     proper  complete     1  convenient   convenient   \n",
       "4           usual     proper  complete     1  convenient   convenient   \n",
       "...           ...        ...       ...   ...         ...          ...   \n",
       "12954  great_pret  very_crit    foster  more    critical       inconv   \n",
       "12955  great_pret  very_crit    foster  more    critical       inconv   \n",
       "12956  great_pret  very_crit    foster  more    critical       inconv   \n",
       "12957  great_pret  very_crit    foster  more    critical       inconv   \n",
       "12958  great_pret  very_crit    foster  more    critical       inconv   \n",
       "\n",
       "             nonprob  recommended   recommend  \n",
       "0            nonprob     priority    priority  \n",
       "1            nonprob    not_recom   not_recom  \n",
       "2      slightly_prob  recommended   recommend  \n",
       "3      slightly_prob     priority    priority  \n",
       "4      slightly_prob    not_recom   not_recom  \n",
       "...              ...          ...         ...  \n",
       "12954  slightly_prob     priority  spec_prior  \n",
       "12955  slightly_prob    not_recom   not_recom  \n",
       "12956    problematic  recommended  spec_prior  \n",
       "12957    problematic     priority  spec_prior  \n",
       "12958    problematic    not_recom   not_recom  \n",
       "\n",
       "[12959 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "file_name = 'nursery.data'\n",
    "df=pd.read_csv(file_name)\n",
    "b= pd.DataFrame(df)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usual' 'proper' 'complete' '1' 'convenient' 'convenient' 'nonprob']\n",
      "['priority' 'not_recom' 'recommend' ... 'spec_prior' 'spec_prior'\n",
      " 'not_recom']\n"
     ]
    }
   ],
   "source": [
    "a=b.values\n",
    "X=a[:,:7]   \n",
    "y=a[:,-1]\n",
    "print(X[1])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "X[:,0]= LE.fit_transform(X[:,0])\n",
    "X[:,1]= LE.fit_transform(X[:,1])\n",
    "X[:,2]= LE.fit_transform(X[:,2])\n",
    "X[:,3]= LE.fit_transform(X[:,3])\n",
    "X[:,4]= LE.fit_transform(X[:,4])\n",
    "X[:,5]= LE.fit_transform(X[:,5])\n",
    "X[:,6]= LE.fit_transform(X[:,6])\n",
    "y= LE.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 0 ... 0 0 0]\n",
      " [2 3 0 ... 0 0 0]\n",
      " [2 3 0 ... 0 0 2]\n",
      " ...\n",
      " [0 4 2 ... 1 1 1]\n",
      " [0 4 2 ... 1 1 1]\n",
      " [0 4 2 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scale=scaler.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # SVM \n",
    "svclassifier = SVC(C=1,kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70 418 350   0]\n",
      " [ 86 511 288   0]\n",
      " [ 68 222 502   0]\n",
      " [  7  68   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.08      0.13       838\n",
      "           1       0.42      0.58      0.49       885\n",
      "           3       0.44      0.63      0.52       792\n",
      "           4       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.42      2592\n",
      "   macro avg       0.29      0.32      0.28      2592\n",
      "weighted avg       0.38      0.42      0.37      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>spec_prior</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>spec_prior</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Actual   Predicted\n",
       "0      not_recom    priority\n",
       "1       priority    priority\n",
       "2      not_recom  spec_prior\n",
       "3       priority  spec_prior\n",
       "4       priority    priority\n",
       "...          ...         ...\n",
       "2587  spec_prior  spec_prior\n",
       "2588  spec_prior  spec_prior\n",
       "2589    priority    priority\n",
       "2590   not_recom    priority\n",
       "2591    priority    priority\n",
       "\n",
       "[2592 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = LE.inverse_transform(y_test)\n",
    "Y2 = LE.inverse_transform(y_pred)\n",
    "df=pd.DataFrame({'Actual':Y1, 'Predicted':Y2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[119 458 261   0]\n",
      " [145 609 131   0]\n",
      " [107 239 446   0]\n",
      " [  0  77   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.14      0.20       838\n",
      "           1       0.44      0.69      0.54       885\n",
      "           3       0.53      0.56      0.55       792\n",
      "           4       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.45      2592\n",
      "   macro avg       0.32      0.35      0.32      2592\n",
      "weighted avg       0.42      0.45      0.41      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB  # NB\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125 369 338   6]\n",
      " [439 361  73  12]\n",
      " [385  50 357   0]\n",
      " [ 42  35   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.15      0.14       838\n",
      "           1       0.44      0.41      0.42       885\n",
      "           3       0.46      0.45      0.46       792\n",
      "           4       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.33      2592\n",
      "   macro avg       0.26      0.25      0.25      2592\n",
      "weighted avg       0.33      0.33      0.33      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.1001266337180977\n",
      "Mean Squared Error: 1.6295264992935437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "regressor = LinearRegression()   \n",
    "regressor.fit(X_train, y_train)   # fit\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 2/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 3/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 4/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 5/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 6/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 7/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 8/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 9/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 10/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 11/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 12/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 13/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 14/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 15/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 16/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 17/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 18/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 19/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 20/100\n",
      "324/324 [==============================] - 0s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 21/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 22/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 23/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 24/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 25/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 26/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 27/100\n",
      "324/324 [==============================] - 1s 3ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 28/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 29/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 30/100\n",
      "324/324 [==============================] - 1s 3ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 31/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 32/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 33/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 34/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 35/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 36/100\n",
      "324/324 [==============================] - 0s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 37/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 38/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 39/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 40/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 41/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 42/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 43/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 44/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 45/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 46/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 47/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 48/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 49/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 50/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 51/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 52/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 53/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 54/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 55/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 56/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 57/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 58/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 59/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 60/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 61/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 62/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 63/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 64/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 65/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 66/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 67/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 68/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 69/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 70/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 71/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 72/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 73/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 74/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 75/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 76/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 77/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 78/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 79/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 80/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 81/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 82/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 83/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 84/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 85/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 86/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 87/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 88/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 89/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 90/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 91/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 92/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 93/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 94/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 95/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 96/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 97/100\n",
      "324/324 [==============================] - 0s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 98/100\n",
      "324/324 [==============================] - 1s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 99/100\n",
      "324/324 [==============================] - 0s 2ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n",
      "Epoch 100/100\n",
      "324/324 [==============================] - 0s 1ms/step - loss: -5.5543 - accuracy: 0.3261 - val_loss: -5.7479 - val_accuracy: 0.3414\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential([Dense(32, activation='relu', input_shape=(7,)),\n",
    "                    Dense(32, activation='relu'),  \n",
    "                    Dense(1, activation='softmax'),])\n",
    "# structure neural network : input layer( size =7) , hidden layer 1 ( size 32),hidden 2 ( size 32) , output \n",
    "# relu function : Rectified Linear Unit ,\n",
    "model.compile(optimizer='sgd',  # stochastic gradient descent, vá»›i multip-class classification nÃªn dÃ¹ng \n",
    "              loss='binary_crossentropy',   \n",
    "              metrics=['accuracy'])\n",
    "         #dung binary_crossentropy thi ra loss nAN\n",
    "X_train=np.asarray(X_train).astype(np.float64)   # chuyen thanh float tranh loi \n",
    "y_train=np.asarray(y_train).astype(np.float64) \n",
    "X_test=np.asarray(X_test).astype(np.float64) \n",
    "y_test=np.asarray(y_test).astype(np.float64)     \n",
    "hist = model.fit(X_train, y_train, epochs=100,batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1daf4e6e7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Abs Error [1000$]')\n",
    "plt.plot(hist.epoch, np.array(hist.history['accuracy']), label='Train accuracy')\n",
    "plt.plot(hist.epoch, np.array(hist.history['val_accuracy']), label = 'Val accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
