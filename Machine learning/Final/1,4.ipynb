{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usual</th>\n",
       "      <th>proper</th>\n",
       "      <th>complete</th>\n",
       "      <th>1</th>\n",
       "      <th>convenient</th>\n",
       "      <th>convenient.1</th>\n",
       "      <th>nonprob</th>\n",
       "      <th>recommended</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   usual  proper  complete  1  convenient convenient.1        nonprob  \\\n",
       "0  usual  proper  complete  1  convenient   convenient        nonprob   \n",
       "1  usual  proper  complete  1  convenient   convenient        nonprob   \n",
       "2  usual  proper  complete  1  convenient   convenient  slightly_prob   \n",
       "3  usual  proper  complete  1  convenient   convenient  slightly_prob   \n",
       "4  usual  proper  complete  1  convenient   convenient  slightly_prob   \n",
       "\n",
       "   recommended  recommend  \n",
       "0     priority   priority  \n",
       "1    not_recom  not_recom  \n",
       "2  recommended  recommend  \n",
       "3     priority   priority  \n",
       "4    not_recom  not_recom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "file_name = 'nursery.data'\n",
    "df=pd.read_csv(file_name)\n",
    "b= pd.DataFrame(df)\n",
    "b.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  (12959, 9)\n",
      "Info of dataset: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12959 entries, 0 to 12958\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   usual         12959 non-null  object\n",
      " 1   proper        12959 non-null  object\n",
      " 2   complete      12959 non-null  object\n",
      " 3   1             12959 non-null  object\n",
      " 4   convenient    12959 non-null  object\n",
      " 5   convenient.1  12959 non-null  object\n",
      " 6   nonprob       12959 non-null  object\n",
      " 7   recommended   12959 non-null  object\n",
      " 8   recommend     12959 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.3+ KB\n",
      "Describe Dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "not_recom     4320\n",
       "priority      4266\n",
       "spec_prior    4044\n",
       "very_recom     328\n",
       "recommend        1\n",
       "Name: recommend, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size of dataset: \", b.shape)\n",
    "print(\"Info of dataset: \")\n",
    "b.info()\n",
    "print(\"Describe Dataset: \")\n",
    "b.describe()\n",
    "duplicate = b[b.duplicated()] \n",
    "duplicate\n",
    "b.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usual' 'proper' 'complete' '1' 'convenient' 'convenient' 'nonprob']\n",
      "['priority' 'not_recom' 'recommend' ... 'spec_prior' 'spec_prior'\n",
      " 'not_recom']\n"
     ]
    }
   ],
   "source": [
    "a=b.values\n",
    "X=a[:,:7]   \n",
    "y=a[:,-1]\n",
    "print(X[1])\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "X[:,0]= LE.fit_transform(X[:,0])\n",
    "X[:,1]= LE.fit_transform(X[:,1])\n",
    "X[:,2]= LE.fit_transform(X[:,2])\n",
    "X[:,3]= LE.fit_transform(X[:,3])\n",
    "X[:,4]= LE.fit_transform(X[:,4])\n",
    "X[:,5]= LE.fit_transform(X[:,5])\n",
    "X[:,6]= LE.fit_transform(X[:,6])\n",
    "y= LE.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 0 ... 0 0 0]\n",
      " [2 3 0 ... 0 0 0]\n",
      " [2 3 0 ... 0 0 2]\n",
      " ...\n",
      " [0 4 2 ... 1 1 1]\n",
      " [0 4 2 ... 1 1 1]\n",
      " [0 4 2 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scale=scaler.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # SVM \n",
    "svclassifier = SVC(C=1,kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 70 418 350   0]\n",
      " [ 86 511 288   0]\n",
      " [ 68 222 502   0]\n",
      " [  7  68   2   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.08      0.13       838\n",
      "           1       0.42      0.58      0.49       885\n",
      "           3       0.44      0.63      0.52       792\n",
      "           4       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.42      2592\n",
      "   macro avg       0.29      0.32      0.28      2592\n",
      "weighted avg       0.38      0.42      0.37      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>spec_prior</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>spec_prior</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>not_recom</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Actual   Predicted\n",
       "0      not_recom    priority\n",
       "1       priority    priority\n",
       "2      not_recom  spec_prior\n",
       "3       priority  spec_prior\n",
       "4       priority    priority\n",
       "...          ...         ...\n",
       "2587  spec_prior  spec_prior\n",
       "2588  spec_prior  spec_prior\n",
       "2589    priority    priority\n",
       "2590   not_recom    priority\n",
       "2591    priority    priority\n",
       "\n",
       "[2592 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = LE.inverse_transform(y_test)\n",
    "Y2 = LE.inverse_transform(y_pred)\n",
    "df=pd.DataFrame({'Actual':Y1, 'Predicted':Y2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict of LR model:  [1. 1. 3. ... 1. 3. 1.]\n",
      "Result:  [0. 1. 0. ... 1. 0. 1.]\n",
      "Probability: 45.29%              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.14      0.20       838\n",
      "         1.0       0.44      0.69      0.54       885\n",
      "         3.0       0.53      0.56      0.55       792\n",
      "         4.0       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.45      2592\n",
      "   macro avg       0.32      0.35      0.32      2592\n",
      "weighted avg       0.42      0.45      0.41      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB  # NB\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,y_pred,zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict of LR model:  [0. 1. 1. ... 1. 0. 0.]\n",
      "Result:  [0. 1. 0. ... 1. 0. 1.]\n",
      "Probability: 32.52%              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.15      0.14       838\n",
      "         1.0       0.44      0.41      0.42       885\n",
      "         3.0       0.46      0.45      0.46       792\n",
      "         4.0       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.33      2592\n",
      "   macro avg       0.26      0.25      0.25      2592\n",
      "weighted avg       0.33      0.33      0.33      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred,zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict of LR model:  [1. 1. 3. ... 1. 1. 1.]\n",
      "Result:  [0. 1. 0. ... 1. 0. 1.]\n",
      "Probability: 42.32%              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.17      0.22       838\n",
      "         1.0       0.43      0.56      0.48       885\n",
      "         3.0       0.47      0.58      0.52       792\n",
      "         4.0       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.42      2592\n",
      "   macro avg       0.30      0.33      0.31      2592\n",
      "weighted avg       0.39      0.42      0.40      2592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred,zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.17      0.22       838\n",
      "         1.0       0.43      0.56      0.48       885\n",
      "         3.0       0.47      0.58      0.52       792\n",
      "         4.0       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.42      2592\n",
      "   macro avg       0.30      0.33      0.31      2592\n",
      "weighted avg       0.39      0.42      0.40      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_MLP = MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50), max_iter=300)\n",
    "model_MLP.fit(X_train, y_train)\n",
    "predict_MLP = model_MLP.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
