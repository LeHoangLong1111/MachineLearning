{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlgwt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  Get >50k        32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlgwt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Get &gt;50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlgwt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      Get >50k  \n",
       "0        <=50K  \n",
       "1        <=50K  \n",
       "2        <=50K  \n",
       "3        <=50K  \n",
       "4        <=50K  \n",
       "...        ...  \n",
       "32556    <=50K  \n",
       "32557     >50K  \n",
       "32558    <=50K  \n",
       "32559    <=50K  \n",
       "32560     >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "df = pd.read_csv('adult.data',names =['age','workclass','fnlgwt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','Get >50k'] )  # read data\n",
    "df.info()   # show type each colums\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 ' Self-emp-not-inc' 83311 ' Bachelors' 13 ' Married-civ-spouse'\n",
      " ' Exec-managerial' ' Husband' ' White' ' Male' 0 0 13 ' United-States']\n",
      "[' <=50K' ' <=50K' ' <=50K' ... ' <=50K' ' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "a=df.values\n",
    "X=a[:,:-1]   \n",
    "y=a[:,-1]\n",
    "print(X[1])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "X[:,1]= LE.fit_transform(X[:,1])\n",
    "X[:,3]= LE.fit_transform(X[:,3])\n",
    "X[:,5]= LE.fit_transform(X[:,5])\n",
    "X[:,6]= LE.fit_transform(X[:,6])\n",
    "X[:,7]= LE.fit_transform(X[:,7])\n",
    "X[:,8]= LE.fit_transform(X[:,8])\n",
    "X[:,9]= LE.fit_transform(X[:,9])\n",
    "X[:,13]= LE.fit_transform(X[:,13])\n",
    "y= LE.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048, 14)\n",
      "Epoch 1/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.7596 - val_loss: 0.1806 - val_accuracy: 0.7677\n",
      "Epoch 2/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.7672 - val_loss: 0.1784 - val_accuracy: 0.7737\n",
      "Epoch 3/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.7688 - val_loss: 0.1756 - val_accuracy: 0.7743\n",
      "Epoch 4/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7677 - val_loss: 0.1761 - val_accuracy: 0.7715\n",
      "Epoch 5/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.7674 - val_loss: 0.1756 - val_accuracy: 0.7726\n",
      "Epoch 6/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.7691 - val_loss: 0.1734 - val_accuracy: 0.7766\n",
      "Epoch 7/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7735 - val_loss: 0.1704 - val_accuracy: 0.7830\n",
      "Epoch 8/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.7803 - val_loss: 0.1734 - val_accuracy: 0.7778\n",
      "Epoch 9/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 10/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 11/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 12/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1720 - val_accuracy: 0.7789\n",
      "Epoch 13/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.7618 - val_loss: 0.1749 - val_accuracy: 0.7778\n",
      "Epoch 14/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.7733 - val_loss: 0.1716 - val_accuracy: 0.7778\n",
      "Epoch 15/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.7740 - val_loss: 0.1718 - val_accuracy: 0.7778\n",
      "Epoch 16/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.7764 - val_loss: 0.1711 - val_accuracy: 0.7811\n",
      "Epoch 17/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.7798 - val_loss: 0.1658 - val_accuracy: 0.7915\n",
      "Epoch 18/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.7842 - val_loss: 0.1643 - val_accuracy: 0.7898\n",
      "Epoch 19/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.7625 - val_loss: 0.1772 - val_accuracy: 0.7778\n",
      "Epoch 20/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 21/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1734 - val_accuracy: 0.7778\n",
      "Epoch 22/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 23/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 24/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1768 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 25/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 26/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 27/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 28/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 29/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 30/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1740 - val_accuracy: 0.7778\n",
      "Epoch 31/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.7730 - val_loss: 0.1746 - val_accuracy: 0.7778\n",
      "Epoch 32/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 33/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 34/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 35/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 36/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 37/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1733 - val_accuracy: 0.7778\n",
      "Epoch 38/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 39/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 40/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 41/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 42/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 43/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 44/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 45/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1772 - val_accuracy: 0.7778\n",
      "Epoch 46/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7778\n",
      "Epoch 47/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7777\n",
      "Epoch 48/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1761 - val_accuracy: 0.7778\n",
      "Epoch 49/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7777\n",
      "Epoch 50/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1736 - val_accuracy: 0.7777\n",
      "Epoch 51/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1737 - val_accuracy: 0.7777\n",
      "Epoch 52/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7777\n",
      "Epoch 53/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7777\n",
      "Epoch 54/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7777\n",
      "Epoch 55/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.7730 - val_loss: 0.1755 - val_accuracy: 0.7778\n",
      "Epoch 56/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7777\n",
      "Epoch 57/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1738 - val_accuracy: 0.7778\n",
      "Epoch 58/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1731 - val_accuracy: 0.7777\n",
      "Epoch 60/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1733 - val_accuracy: 0.7777\n",
      "Epoch 61/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.77 - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1738 - val_accuracy: 0.7777\n",
      "Epoch 62/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1737 - val_accuracy: 0.7777\n",
      "Epoch 63/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7777\n",
      "Epoch 64/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7777\n",
      "Epoch 65/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 66/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 67/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 68/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 69/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1740 - val_accuracy: 0.7778\n",
      "Epoch 70/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1734 - val_accuracy: 0.7777\n",
      "Epoch 71/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 72/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1746 - val_accuracy: 0.7778\n",
      "Epoch 73/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7778\n",
      "Epoch 74/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 75/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 76/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 77/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1740 - val_accuracy: 0.7778\n",
      "Epoch 78/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 79/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 80/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1735 - val_accuracy: 0.7778\n",
      "Epoch 81/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 82/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7730 - val_loss: 0.1737 - val_accuracy: 0.7778\n",
      "Epoch 83/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1743 - val_accuracy: 0.7778\n",
      "Epoch 84/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 85/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 86/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 87/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 88/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 89/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 90/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 91/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7778\n",
      "Epoch 92/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 93/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1734 - val_accuracy: 0.7778\n",
      "Epoch 94/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 95/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 96/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 97/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 98/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1738 - val_accuracy: 0.7778\n",
      "Epoch 99/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 100/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 101/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 102/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 103/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7778\n",
      "Epoch 104/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 105/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7730 - val_loss: 0.1732 - val_accuracy: 0.7778\n",
      "Epoch 106/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7730 - val_loss: 0.1757 - val_accuracy: 0.7777\n",
      "Epoch 107/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 108/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1751 - val_accuracy: 0.7777\n",
      "Epoch 109/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1740 - val_accuracy: 0.7777\n",
      "Epoch 110/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 111/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 112/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1752 - val_accuracy: 0.7778\n",
      "Epoch 113/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 114/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 115/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7730 - val_loss: 0.1731 - val_accuracy: 0.7778\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 117/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1740 - val_accuracy: 0.7778\n",
      "Epoch 118/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 119/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1731 - val_accuracy: 0.7778\n",
      "Epoch 120/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 121/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 122/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 123/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 124/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 125/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 126/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 127/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 128/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 129/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 130/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 131/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 132/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 133/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1756 - val_accuracy: 0.7778\n",
      "Epoch 134/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 135/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7778\n",
      "Epoch 136/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 137/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 138/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 139/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 140/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1737 - val_accuracy: 0.7778\n",
      "Epoch 141/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 142/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.7730 - val_loss: 0.1729 - val_accuracy: 0.7778\n",
      "Epoch 143/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 144/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1733 - val_accuracy: 0.7777\n",
      "Epoch 145/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 146/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7778\n",
      "Epoch 147/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 148/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1741 - val_accuracy: 0.7777\n",
      "Epoch 149/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 150/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.7730 - val_loss: 0.1731 - val_accuracy: 0.7778\n",
      "Epoch 151/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1739 - val_accuracy: 0.7778\n",
      "Epoch 152/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 153/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1733 - val_accuracy: 0.7777\n",
      "Epoch 154/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 155/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 156/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.77 - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1733 - val_accuracy: 0.7778\n",
      "Epoch 157/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 158/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 159/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.7730 - val_loss: 0.1728 - val_accuracy: 0.7778\n",
      "Epoch 160/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 161/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 162/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1727 - val_accuracy: 0.7778\n",
      "Epoch 163/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7777\n",
      "Epoch 164/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7730 - val_loss: 0.1730 - val_accuracy: 0.7777\n",
      "Epoch 165/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1726 - val_accuracy: 0.7777\n",
      "Epoch 166/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7730 - val_loss: 0.1725 - val_accuracy: 0.7778\n",
      "Epoch 167/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.7350 - val_loss: 0.1770 - val_accuracy: 0.7691\n",
      "Epoch 168/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.7640 - val_loss: 0.1771 - val_accuracy: 0.7691\n",
      "Epoch 169/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7637 - val_loss: 0.1767 - val_accuracy: 0.7691\n",
      "Epoch 170/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.7656 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 171/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 172/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 174/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 175/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 176/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 177/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 178/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 179/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 180/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 181/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 182/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 183/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 184/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 185/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 186/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 187/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1771 - val_accuracy: 0.7718\n",
      "Epoch 188/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 189/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 190/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 191/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 192/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1780 - val_accuracy: 0.7718\n",
      "Epoch 193/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 194/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 195/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 196/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 197/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 198/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.7662 - val_loss: 0.1771 - val_accuracy: 0.7718\n",
      "Epoch 199/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 200/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 201/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1775 - val_accuracy: 0.7718\n",
      "Epoch 202/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 203/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1793 - val_accuracy: 0.7718\n",
      "Epoch 204/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 205/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 206/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 207/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 208/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 209/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 210/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 211/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 212/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 213/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 214/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1785 - val_accuracy: 0.7718\n",
      "Epoch 215/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1773 - val_accuracy: 0.7718\n",
      "Epoch 216/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 217/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 218/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 219/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1771 - val_accuracy: 0.7718\n",
      "Epoch 220/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 221/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 222/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 223/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 224/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 225/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 226/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 227/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 228/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 229/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 231/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 232/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 233/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 234/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 235/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 236/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 237/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 238/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1768 - val_accuracy: 0.7718\n",
      "Epoch 239/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 240/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 241/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 242/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 243/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 244/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 245/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 246/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 247/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 248/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 249/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 250/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 251/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 252/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 253/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 254/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 255/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 256/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 257/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 258/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 259/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 260/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 261/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 262/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 263/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1774 - val_accuracy: 0.7718\n",
      "Epoch 264/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 265/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 266/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 267/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 268/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 269/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 270/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 271/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 272/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 273/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 274/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 275/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 276/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1768 - val_accuracy: 0.7718\n",
      "Epoch 277/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1769 - val_accuracy: 0.7718\n",
      "Epoch 278/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 279/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 280/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 281/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 282/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 283/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 284/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 285/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 286/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 288/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 289/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 290/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 291/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 292/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 293/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 294/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 295/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 296/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 297/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 298/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 299/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 300/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 301/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 302/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1772 - val_accuracy: 0.7718\n",
      "Epoch 303/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 304/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 305/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1773 - val_accuracy: 0.7718\n",
      "Epoch 306/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 307/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 308/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1768 - val_accuracy: 0.7718\n",
      "Epoch 309/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 310/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 311/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 312/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 313/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 314/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1771 - val_accuracy: 0.7718\n",
      "Epoch 315/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 316/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 317/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 318/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 319/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 320/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 321/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 322/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 323/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 324/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 325/500\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 326/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 327/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 328/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 329/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 330/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 331/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 332/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 333/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 334/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 335/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 336/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 337/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1785 - val_accuracy: 0.7718\n",
      "Epoch 338/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 339/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 340/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 341/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 342/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 343/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 345/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 346/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 347/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 348/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 349/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 350/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 351/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 352/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 353/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 354/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 355/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 356/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 357/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 358/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 359/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 360/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 361/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 362/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 363/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 364/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 365/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 366/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 367/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 368/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 369/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 370/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 371/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 372/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 373/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 374/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1766 - val_accuracy: 0.7718\n",
      "Epoch 375/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1773 - val_accuracy: 0.7718\n",
      "Epoch 376/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 377/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 378/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 379/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 380/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 381/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 382/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 383/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 384/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 385/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 386/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 387/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 388/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 389/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 390/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 391/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 392/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 393/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 394/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 395/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 396/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 397/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 398/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 399/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 400/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 402/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 403/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 404/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 405/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 406/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 407/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 408/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 409/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 410/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1768 - val_accuracy: 0.7718\n",
      "Epoch 411/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 412/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 413/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 414/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 415/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 416/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 417/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 418/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 419/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 420/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1771 - val_accuracy: 0.7718\n",
      "Epoch 421/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 422/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 423/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 424/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 425/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 426/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 427/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 428/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 429/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 430/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 431/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 432/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 433/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 434/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 435/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 436/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 437/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 438/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 439/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 440/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 441/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 442/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 443/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1764 - val_accuracy: 0.7718\n",
      "Epoch 444/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 445/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1762 - val_accuracy: 0.7718\n",
      "Epoch 446/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 447/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 448/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 449/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 450/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 451/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 452/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 453/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 454/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 455/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 456/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 457/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1767 - val_accuracy: 0.7718\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 459/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 460/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 461/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 462/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 463/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 464/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 465/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 466/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 467/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 468/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 469/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1773 - val_accuracy: 0.7718\n",
      "Epoch 470/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 471/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 472/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 473/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 474/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.7662 - val_loss: 0.1765 - val_accuracy: 0.7718\n",
      "Epoch 475/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 476/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 477/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 478/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 479/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 480/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 481/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 482/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 483/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 484/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 485/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1763 - val_accuracy: 0.7718\n",
      "Epoch 486/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 487/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 488/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 489/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 490/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 491/500\n",
      "53/53 [==============================] - 0s 8ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n",
      "Epoch 492/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 493/500\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1759 - val_accuracy: 0.7718\n",
      "Epoch 494/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 495/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 496/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 497/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 498/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7662 - val_loss: 0.1758 - val_accuracy: 0.7718\n",
      "Epoch 499/500\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.7662 - val_loss: 0.1760 - val_accuracy: 0.7718\n",
      "Epoch 500/500\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.7662 - val_loss: 0.1761 - val_accuracy: 0.7718\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([Dense(32, activation='tanh', input_dim=14),\n",
    "                    Dense(32, activation='tanh'),  \n",
    "                    Dense(1, activation='tanh'),])\n",
    "# structure neural network : input 14 , hidden layer 1 ( size 32),hidden 2 ( size 32) , output \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',  # stochastic gradient descent, vá»›i multip-class classification nÃªn dÃ¹ng \n",
    "              loss='mean_squared_error',   \n",
    "              metrics=['accuracy'])\n",
    "         #dung binary_crossentropy thi ra loss nAN\n",
    "X_train=np.asarray(X_train).astype(np.float64)   # chuyen thanh float tranh loi \n",
    "y_train=np.asarray(y_train).astype(np.float64) \n",
    "X_test=np.asarray(X_test).astype(np.float64) \n",
    "y_test=np.asarray(y_test).astype(np.float64) \n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "# Má»™t Epoch Ä‘Æ°á»£c tÃ­nh lÃ  khi chÃºng ta Ä‘Æ°a táº¥t cáº£ dá»¯ liá»‡u vÃ o máº¡ng neural network 1 láº§n. Ä‘em toÃ n bá»™ dá»¯ liá»‡u qua máº¡ng má»™t vÃ i láº§n Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c káº¿t quáº£ tá»‘i Æ°u\n",
    "# Batch_size lÃ  sá»‘ lÆ°á»£ng máº«u dá»¯ liá»‡u trong má»™t batch  \n",
    "# => cÃ³ 26048 táº­p dá»¯ liá»‡u máº«u , batch_size = 50 => iterations 521 ( sá»‘ lÆ°á»£ng batch cáº§n Ä‘á»ƒ hoÃ n thÃ nh 1 epoch)\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs=500,batch_size=500,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b6aeb22a60>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist.epoch, np.array(hist.history['loss']), label='loss')\n",
    "plt.plot(hist.epoch, np.array(hist.history['val_loss']), label = 'Val loss')\n",
    "plt.legend(['train', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
